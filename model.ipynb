{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63fd59dc",
   "metadata": {},
   "source": [
    "## ED5005 MSC AI PROJECT\n",
    "\n",
    "### Title: Analysis of how semantic similarity methods can be used to automatically test call routing in Interactive Voice Response Systems\n",
    "\n",
    "### Objective: The objective of this script is to to use variations of BERT pretrained models on the clean ivr data and calculate the semantic similarity between the intent and the child_transcription using cosine similarity, pearsons correlation and spearmans correlation\n",
    "\n",
    "Student Name: Brian Mullins\n",
    "\n",
    "Student Number: 19225741"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9a47ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the libraries and clean ivr data\n",
    "import json \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import spatial\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import gensim.downloader as api\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "df = pd.read_csv('clean_ivr_data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a530277c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create models for GloVe and the different variations of BERT\n",
    "glove_model = api.load(\"glove-wiki-gigaword-50\") #choose from multiple models https://github.com/RaRe-Technologies/gensim-data\n",
    "word2vec_model = api.load('word2vec-google-news-300')\n",
    "bert_model = SentenceTransformer('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "roberta_model = SentenceTransformer('sentence-transformers/nli-roberta-base')\n",
    "tinybert_model = SentenceTransformer('sentence-transformers/paraphrase-TinyBERT-L6-v2')\n",
    "albert_model = SentenceTransformer('sentence-transformers/paraphrase-albert-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a47c4e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_info = api.info('glove-wiki-gigaword-50')\n",
    "print(json.dumps(glove_info, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39e517ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_info = api.info('word2vec-google-news-300')\n",
    "print(json.dumps(word2vec_info, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff72efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index, row in df.iterrows():\n",
    "    ###########################################################################################\n",
    "    # Create BERT embedding and calculate cosine similarity, pearsons and spearmans correlation\n",
    "    ###########################################################################################\n",
    "    \n",
    "    bert_child_embeddings = bert_model.encode(str(row['child_transcription_without_stopwords']))\n",
    "    bert_intent_embeddings = bert_model.encode(str(row['intent_without_stopwords']))\n",
    "    \n",
    "    # calculate cosine simlarity\n",
    "    bert_cosine_score = spatial.distance.cosine(bert_child_embeddings, bert_intent_embeddings)\n",
    "    #bert_cosine_score_2 = cosine_similarity(bert_child_embeddings, bert_intent_embeddings)\n",
    "    \n",
    "    # calculate Pearson's correlation\n",
    "    bert_pearson_score, _ = pearsonr(bert_child_embeddings, bert_intent_embeddings)\n",
    "    \n",
    "    # calculate spearman's correlation\n",
    "    bert_spearman_score, _ = spearmanr(bert_child_embeddings, bert_intent_embeddings)\n",
    "    \n",
    "    #############################################################################################\n",
    "    # Create RoBerta embedding and calculate cosine similarity, pearsons and spearmans correlation\n",
    "    #############################################################################################\n",
    "    roberta_child_embeddings = roberta_model.encode(str(row['child_transcription_without_stopwords']))\n",
    "    roberta_intent_embeddings = roberta_model.encode(str(row['intent_without_stopwords']))\n",
    "    \n",
    "    # calculate cosine simlarity\n",
    "    roberta_cosine_score = spatial.distance.cosine(roberta_child_embeddings, roberta_intent_embeddings)\n",
    "    #roberta_cosine_score_2 = cosine_similarity(bert_child_embeddings, bert_intent_embeddings)\n",
    "    \n",
    "    # calculate Pearson's correlation\n",
    "    roberta_pearson_score, _ = pearsonr(roberta_child_embeddings, roberta_intent_embeddings)\n",
    "    \n",
    "    # calculate spearman's correlation\n",
    "    roberta_spearman_score, _ = spearmanr(roberta_child_embeddings, roberta_intent_embeddings)\n",
    "    \n",
    "    ##############################################################################################\n",
    "    # Create TinyBert embedding and calculate cosine similarity, pearsons and spearmans correlaton\n",
    "    ##############################################################################################\n",
    "    tinybert_child_embeddings = tinybert_model.encode(str(row['child_transcription_without_stopwords']))\n",
    "    tinybert_intent_embeddings = tinybert_model.encode(str(row['intent_without_stopwords']))\n",
    "    \n",
    "    # calculate cosine simlarity\n",
    "    tinybert_cosine_score = spatial.distance.cosine(tinybert_child_embeddings, tinybert_intent_embeddings)\n",
    "    #tinybert_cosine_score_2 = cosine_similarity(bert_child_embeddings, bert_intent_embeddings)\n",
    "    \n",
    "    # calculate Pearson's correlation\n",
    "    tinybert_pearson_score, _ = pearsonr(tinybert_child_embeddings, tinybert_intent_embeddings)\n",
    "    \n",
    "    # calculate spearman's correlation\n",
    "    tinybert_spearman_score, _ = spearmanr(tinybert_child_embeddings, tinybert_intent_embeddings)\n",
    "    \n",
    "    #############################################################################################\n",
    "    # Create AlBert embedding and calculate cosine similarity, pearsons and spearmans correlaton\n",
    "    #############################################################################################\n",
    "    albert_child_embeddings = albert_model.encode(str(row['child_transcription_without_stopwords']))\n",
    "    albert_intent_embeddings = albert_model.encode(str(row['intent_without_stopwords']))\n",
    "    \n",
    "    # calculate cosine simlarity\n",
    "    albert_cosine_score = spatial.distance.cosine(albert_child_embeddings, albert_intent_embeddings)\n",
    "    #albert_cosine_score_2 = cosine_similarity(bert_child_embeddings, bert_intent_embeddings)\n",
    "    \n",
    "    # calculate Pearson's correlation\n",
    "    albert_pearson_score, _ = pearsonr(albert_child_embeddings, albert_intent_embeddings)\n",
    "    \n",
    "    # calculate spearman's correlation\n",
    "    albert_spearman_score, _ = spearmanr(albert_child_embeddings, albert_intent_embeddings)\n",
    "    \n",
    "    ############################################################################################\n",
    "    # Create Glove embedding and calculate cosine similarity, pearsons and spearmans correlaton\n",
    "    ###########################################################################################\n",
    "    glove_error = 0\n",
    "    child_transcription  = list(str(row['child_transcription_without_stopwords']).split(\" \"))\n",
    "    intent  = list(str(row['intent_without_stopwords']).split(\" \"))\n",
    "    vector_1 = np.mean([glove_model[word] for word in child_transcription if word in glove_model],axis=0)\n",
    "    vector_2 = np.mean([glove_model[word] for word in intent if word in glove_model],axis=0)\n",
    "\n",
    "    # calculate cosine simlarity\n",
    "    try:\n",
    "        glove_cosine_score = spatial.distance.cosine(vector_1, vector_2)\n",
    "\n",
    "        # calculate Pearson's correlation\n",
    "        glove_pearson_score, _ = pearsonr(vector_1, vector_2)\n",
    "     \n",
    "        # calculate spearman's correlation\n",
    "        glove_spearman_score, _ = spearmanr(vector_1, vector_2)\n",
    "       \n",
    "    except:\n",
    "        glove_cosine_score = None\n",
    "        # calculate Pearson's correlation\n",
    "        glove_pearson_score = None\n",
    "\n",
    "        # calculate spearman's correlation\n",
    "        glove_spearman_score = None\n",
    "        glove_error = 1\n",
    "        \n",
    "    ############################################################################################\n",
    "    # Create word2vec embedding and calculate cosine similarity, pearsons and spearmans correlaton\n",
    "    ###########################################################################################\n",
    "    word2vec_error = 0\n",
    "    child_transcription  = list(str(row['child_transcription_without_stopwords']).split(\" \"))\n",
    "    intent  = list(str(row['intent_without_stopwords']).split(\" \"))\n",
    "    vector_1 = np.mean([word2vec_model[word] for word in child_transcription if word in word2vec_model],axis=0)\n",
    "    vector_2 = np.mean([word2vec_model[word] for word in intent if word in word2vec_model],axis=0)\n",
    "    \n",
    "    # calculate cosine simlarity\n",
    "    try:\n",
    "        word2vec_cosine_score = spatial.distance.cosine(vector_1, vector_2)\n",
    "\n",
    "        # calculate Pearson's correlation\n",
    "        word2vec_pearson_score, _ = pearsonr(vector_1, vector_2)\n",
    "     \n",
    "        # calculate spearman's correlation\n",
    "        word2vec_spearman_score, _ = spearmanr(vector_1, vector_2)\n",
    "       \n",
    "    except:\n",
    "        word2veccosine_score = None\n",
    "        # calculate Pearson's correlation\n",
    "        word2vec_pearson_score = None\n",
    "\n",
    "        # calculate spearman's correlation\n",
    "        word2vec_spearman_score = None\n",
    "        word2vec_error = 1\n",
    "        \n",
    "    \n",
    "    #####################################################################################\n",
    "    # Write results back into dataframe\n",
    "    #####################################################################################\n",
    "    #cosine\n",
    "    df.loc[index, 'bert_cosine_score'] = 1 - bert_cosine_score\n",
    "    df.loc[index, 'tinybert_cosine_score'] = 1 - tinybert_cosine_score\n",
    "    df.loc[index, 'roberta_cosine_score'] = 1 - roberta_cosine_score\n",
    "    df.loc[index, 'albert_cosine_score'] = 1 - albert_cosine_score\n",
    "    if glove_cosine_score is not None:\n",
    "        df.loc[index, 'glove_cosine_score'] = 1 - glove_cosine_score\n",
    "    if word2vec_cosine_score is not None:\n",
    "        df.loc[index, 'word2vec_cosine_score'] = 1 - word2vec_cosine_score\n",
    "    \n",
    "    \n",
    "    #pearsons score\n",
    "    df.loc[index, 'bert_pearson_score'] = bert_pearson_score\n",
    "    df.loc[index, 'tinybert_pearson_score'] = tinybert_pearson_score\n",
    "    df.loc[index, 'roberta_pearson_score'] = roberta_pearson_score\n",
    "    df.loc[index, 'albert_pearson_score'] = albert_pearson_score\n",
    "    df.loc[index, 'glove_pearson_score'] = glove_pearson_score\n",
    "    df.loc[index, 'word2vec_pearson_score'] = word2vec_pearson_score\n",
    "    \n",
    "    #spearmans\n",
    "    df.loc[index, 'bert_spearman_score'] = bert_spearman_score\n",
    "    df.loc[index, 'roberta_spearman_score'] = roberta_spearman_score\n",
    "    df.loc[index, 'tinybert_spearman_score'] = tinybert_spearman_score\n",
    "    df.loc[index, 'albert_spearman_score'] = albert_spearman_score\n",
    "    df.loc[index, 'glove_spearman_score'] = glove_spearman_score\n",
    "    df.loc[index, 'word2vec_spearman_score'] = word2vec_spearman_score\n",
    "    \n",
    "    #log if error was present on glove model\n",
    "    df.loc[index, 'glove_error'] = glove_error\n",
    "    df.loc[index, 'word2vec_error'] = word2vec_error\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827450d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ab5c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save cleaned data to csv\n",
    "df.to_csv('results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f7a48b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
